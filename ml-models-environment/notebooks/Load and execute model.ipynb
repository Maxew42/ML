{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfa7b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import csv\n",
    "random.seed(4)\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "#import albumentations as A\n",
    "import cv2\n",
    "from helpers.plotting import *\n",
    "from helpers.ml_utils import *\n",
    "## A nettoyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac466c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Parametrisation ###\n",
    "\n",
    "model_path = \"../saved_models/model_SGD_balanced_1.3_412x412_no_kebab/model_SGD_balanced_1.3_412x412_no_kebab\"\n",
    "name_dataset = 'dataset_trashedy_1.3_augmented_412x412'\n",
    "path_to_data = '../dataset/'+ name_dataset + '/train/'\n",
    "device      = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cat_to_index = {'other': 1, \n",
    "                'pet': 2,\n",
    "                'plastic_bag' : 3\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3831dd0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = ObjectDetectionDataset(path_to_dataset = path_to_data,  \n",
    "                                       transform = tensor_transform,\n",
    "                                       mapping = cat_to_index,\n",
    "                                       mode = 'test')\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19af7f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64eb9070",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/676 [00:00<?, ?it/s]C:\\Users\\diabo\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  6%|████▊                                                                            | 40/676 [03:05<49:09,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de l'évaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_to(data_loader,device,cat_to_index,40,model,detection_threshold = 0.33,erase_overlaping_boxes = True)\n",
    "print(\"Fin de l'évaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76837af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Images avec 172 objets detectés\n"
     ]
    }
   ],
   "source": [
    "l_file_name = np.unique([row['file_name'] for row in results])\n",
    "n_file_name = len(l_file_name)\n",
    "n_objects = len(results)\n",
    "print(\"{} Images avec {} objets detectés\".format(n_file_name,n_objects))\n",
    "idx = int(input(\"Entrer indice de l'image à afficher : \"))\n",
    "color_map = {'other': 'red','pet':'blue','plastic_bag':'orange'}\n",
    "show_result(results,path_to_data , l_file_name[idx],color_map = color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28071ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arg(\"-p\", \"--predictions\", type=str, help=\"Json with predictions.\", required=True)\n",
    "#arg(\"-g\", \"--ground_truth\", type=str, help=\"Json with ground truth.\", required=True)\n",
    "#arg(\"-t\", \"--iou_threshold\", type=float, help=\"Iou threshold\", default=0.5)\n",
    "iou_treshold = 0.3\n",
    "\n",
    "gt_annotations = gt[\"annotations\"]\n",
    "categories = gt[\"categories\"]\n",
    "\n",
    "gt_by_id = group_by_key(gt_annotations, \"category_id\")\n",
    "pred_by_id = group_by_key(pred, \"category_id\")\n",
    "\n",
    "    print(gt_by_id.keys())\n",
    "    print(pred_by_id.keys())\n",
    "\n",
    "#category2name = get_category2name(categories)\n",
    "category2name = OrderedDict()\n",
    "category2name[\"1\"] = \"other\"\n",
    "category2name[\"2\"] = \"pet\"\n",
    "category2name[\"3\"] = \"plastic_bag\"\n",
    "num_class_names = len(category2name.values())\n",
    "\n",
    "print(\"Class_names in ground truth = \", sorted(category2name.values()))\n",
    "\n",
    "aps = np.zeros(num_class_names)\n",
    "\n",
    "class_names: List[str] = []\n",
    "\n",
    "for i, category_id in enumerate(category2name.keys()):\n",
    "    if category_id in pred_by_id:  # if we predicted at leas one object for this class.\n",
    "        recalls, precisions, average_precision = recall_precision(\n",
    "            gt_by_id[category_id], pred_by_id[category_id], args.iou_threshold\n",
    "        )\n",
    "        aps[i] = average_precision\n",
    "\n",
    "    class_names += [category2name[category_id]]\n",
    "\n",
    "mAP = np.mean(aps)\n",
    "print(\"Average per class mean average precision = \", mAP)\n",
    "\n",
    "for j in sorted(zip(class_names, aps.flatten().tolist())):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b333273",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Script to calculate mean average precision for a fixed Intersection Over Union (IOU)\n",
    "Expects input data in the COCO format.\n",
    "Based on https://github.com/ucbdrive/bdd-data/blob/master/bdd_data/evaluate.py\n",
    "\"\"\"\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_envelope(precisions: np.ndarray) -> np.array:\n",
    "    \"\"\"Compute the envelope of the precision curve.\n",
    "    Args:\n",
    "      precisions:\n",
    "    Returns: enveloped precision\n",
    "    \"\"\"\n",
    "    for i in range(precisions.size - 1, 0, -1):\n",
    "        precisions[i - 1] = np.maximum(precisions[i - 1], precisions[i])\n",
    "    return precisions\n",
    "\n",
    "\n",
    "def get_ap(recalls: np.ndarray, precisions: np.ndarray) -> float:\n",
    "    \"\"\"Calculate area under precision/recall curve.\n",
    "    Args:\n",
    "      recalls:\n",
    "      precisions:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    recalls = np.concatenate(([0.0], recalls, [1.0]))\n",
    "    precisions = np.concatenate(([0.0], precisions, [0.0]))\n",
    "\n",
    "    precisions = get_envelope(precisions)\n",
    "\n",
    "    # to calculate area under PR curve, look for points where X axis (recall) changes value\n",
    "    i = np.where(recalls[1:] != recalls[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((recalls[i + 1] - recalls[i]) * precisions[i + 1])\n",
    "    return ap\n",
    "\n",
    "\n",
    "def get_overlaps(gt_boxes: np.ndarray, box: np.ndarray) -> np.ndarray:\n",
    "    i_xmin = np.maximum(gt_boxes[:, 0], box[0])\n",
    "    i_ymin = np.maximum(gt_boxes[:, 1], box[1])\n",
    "\n",
    "    gt_xmax = gt_boxes[:, 0] + gt_boxes[:, 2]\n",
    "    gt_ymax = gt_boxes[:, 1] + gt_boxes[:, 3]\n",
    "\n",
    "    box_xmax = box[0] + box[2]\n",
    "    box_ymax = box[1] + box[3]\n",
    "\n",
    "    i_xmax = np.minimum(gt_xmax, box_xmax)\n",
    "    i_ymax = np.minimum(gt_ymax, box_ymax)\n",
    "\n",
    "    iw = np.maximum(i_xmax - i_xmin, 0.0)\n",
    "    ih = np.maximum(i_ymax - i_ymin, 0.0)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    union = box[2] * box[3] + gt_boxes[:, 2] * gt_boxes[:, 3] - intersection\n",
    "\n",
    "    overlaps = intersection / (union + 1e-7)\n",
    "\n",
    "    return overlaps\n",
    "\n",
    "\n",
    "def recall_precision(\n",
    "    gt: np.ndarray, predictions: np.ndarray, iou_threshold: float\n",
    ") -> Tuple[np.array, np.array, np.array]:\n",
    "    num_gts = len(gt)\n",
    "    image_gts = group_by_key(gt, \"image_id\")\n",
    "\n",
    "    image_gt_boxes = {\n",
    "        img_id: np.array([[float(z) for z in b[\"bbox\"]] for b in boxes]) for img_id, boxes in image_gts.items()\n",
    "    }\n",
    "    image_gt_checked = {img_id: np.zeros(len(boxes)) for img_id, boxes in image_gts.items()}\n",
    "\n",
    "    predictions = sorted(predictions, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    num_predictions = len(predictions)\n",
    "    tp = np.zeros(num_predictions)\n",
    "    fp = np.zeros(num_predictions)\n",
    "\n",
    "    for prediction_index, prediction in enumerate(predictions):\n",
    "        box = prediction[\"bbox\"]\n",
    "\n",
    "        max_overlap = -np.inf\n",
    "        jmax = -1\n",
    "\n",
    "        try:\n",
    "            gt_boxes = image_gt_boxes[prediction[\"image_id\"]]  # gt_boxes per image\n",
    "            gt_checked = image_gt_checked[prediction[\"image_id\"]]  # gt flags per image\n",
    "        except KeyError:\n",
    "            gt_boxes = []\n",
    "            gt_checked = None\n",
    "\n",
    "        if len(gt_boxes) > 0:\n",
    "            overlaps = get_overlaps(gt_boxes, box)\n",
    "\n",
    "            max_overlap = np.max(overlaps)\n",
    "            jmax = np.argmax(overlaps)\n",
    "\n",
    "        if max_overlap >= iou_threshold:\n",
    "            if gt_checked[jmax] == 0:\n",
    "                tp[prediction_index] = 1.0\n",
    "                gt_checked[jmax] = 1\n",
    "            else:\n",
    "                fp[prediction_index] = 1.0\n",
    "        else:\n",
    "            fp[prediction_index] = 1.0\n",
    "\n",
    "    # compute precision recall\n",
    "    fp = np.cumsum(fp, axis=0)\n",
    "    tp = np.cumsum(tp, axis=0)\n",
    "\n",
    "    recalls = tp / float(num_gts)\n",
    "\n",
    "    # avoid divide by zero in case the first detection matches a difficult ground truth\n",
    "    precisions = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "\n",
    "    ap = get_ap(recalls, precisions)\n",
    "\n",
    "    return recalls, precisions, ap\n",
    "\n",
    "\n",
    "def get_category2name(categories: List[Dict[str, Any]]) -> OrderedDict:\n",
    "    \"\"\"Creates mapping from category_id to category_name\n",
    "    Args:\n",
    "        categories: list of the type:\n",
    "            \"categories\": [\n",
    "                {\"id\": 1,\"name\": \"person\"},\n",
    "                {\"id\": 2,\"name\": \"bicycle\"},\n",
    "                {\"id\": 3,\"name\": \"car\"},\n",
    "                {\"id\": 4,\"name\": \"motorcycle\"},\n",
    "                {\"id\": 5,\"name\": \"airplane\"},\n",
    "                ...\n",
    "                {\"id\": 89,\"name\": \"hair drier\"},\n",
    "                {\"id\": 90,\"name\": \"toothbrush\"}\n",
    "            ]\n",
    "    Returns: {<category_id>: <name>}\n",
    "    \"\"\"\n",
    "    result = OrderedDict()\n",
    "    for element in categories:\n",
    "        result[element[\"id\"]] = element[\"name\"]\n",
    "    return result\n",
    "\n",
    "def group_by_key(list_dicts: List[dict], key: Any) -> defaultdict:\n",
    "    \"\"\"Groups list of dictionaries by key.\n",
    "    >>> c = [{\"a\": 1, \"b\": \"Wednesday\"}, {\"a\": (1, 2, 3), \"b\": 16.5}]\n",
    "    defaultdict(list,\n",
    "            {1: [{'a': 1, 'b': 'Wednesday'}],\n",
    "             (1, 2, 3): [{'a': (1, 2, 3), 'b': 16.5}]})\n",
    "    Args:\n",
    "        list_dicts:\n",
    "        key:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    groups: defaultdict = defaultdict(list)\n",
    "    for detection in list_dicts:\n",
    "        groups[detection[key]].append(detection)\n",
    "    return groups\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
