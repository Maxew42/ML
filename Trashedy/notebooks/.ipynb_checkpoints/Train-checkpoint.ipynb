{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b362174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import csv\n",
    "random.seed(4)\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "# Non propre A DELETE\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "# ENDELETE\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.nn.functional as func\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "## A nettoyer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "## En evaluation\n",
    "import helpers.engine as eng # Needs debugging\n",
    "from helpers.plotting import *\n",
    "from helpers.ml_utils import *\n",
    "#Temporary\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cc6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINITION DES FONCTIONS ###\n",
    "def fastrcnn_loss_rebranded(class_logits, box_regression, labels, regression_targets):\n",
    "    # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]\n",
    "    \"\"\"\n",
    "    Computes the loss for Faster R-CNN.\n",
    "    Args:\n",
    "        class_logits (Tensor)\n",
    "        box_regression (Tensor)\n",
    "        labels (list[BoxList])\n",
    "        regression_targets (Tensor)\n",
    "    Returns:\n",
    "        classification_loss (Tensor)\n",
    "        box_loss (Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    regression_targets = torch.cat(regression_targets, dim=0)\n",
    "\n",
    "    classification_loss = func.cross_entropy(class_logits, labels,weight = AA_WEIGHTS_ZZ)\n",
    "\n",
    "    # get indices that correspond to the regression targets for\n",
    "    # the corresponding ground truth labels, to be used with\n",
    "    # advanced indexing\n",
    "    sampled_pos_inds_subset = torch.where(labels > 0)[0]\n",
    "    labels_pos = labels[sampled_pos_inds_subset]\n",
    "    N, num_classes = class_logits.shape\n",
    "    box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)\n",
    "\n",
    "    box_loss = func.smooth_l1_loss(\n",
    "        box_regression[sampled_pos_inds_subset, labels_pos],\n",
    "        regression_targets[sampled_pos_inds_subset],\n",
    "        beta=1 / 9,\n",
    "        reduction='sum',\n",
    "    )\n",
    "    box_loss = box_loss / labels.numel()\n",
    "\n",
    "    return classification_loss, box_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5088a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIG ###\n",
    "\n",
    "model_path = \"../saved_models/model3SGD\"\n",
    "path_to_data = '../dataset/dataset_Trashedy_1.0/train/'\n",
    "path_to_validation_data = '../dataset/dataset_Trashedy_1.0/valid/'\n",
    "model_save_name = \"model_SGD_balanced\"\n",
    "device      = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cat_to_index = {'other': 1, \n",
    "                'pet': 2,   \n",
    "                'plastic_bag' : 3\n",
    "                }\n",
    "num_classes = len(cat_to_index)+1\n",
    "loss_value  = 0.0\n",
    "num_epochs  = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eade7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD DATASET ###\n",
    "\n",
    "tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ObjectDetectionDataset(path_to_dataset = path_to_data,  \n",
    "                                       transform = tensor_transform,\n",
    "                                       mapping = cat_to_index,\n",
    "                                       mode = 'train')\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "validation_dataset = ObjectDetectionDataset(path_to_dataset = path_to_validation_data,  \n",
    "                                       transform = tensor_transform,\n",
    "                                       mapping = cat_to_index,\n",
    "                                       mode = 'valid')\n",
    "\n",
    "validation_data_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9485208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', list(cat_to_index.keys()),validation_dataset.data['classes'].to_numpy())\n",
    "class_weights = np.insert(class_weights, 0,np.mean(class_weights) ) #Inserting the weight for the background, BUT HOW TO CHOOSE IT ????\n",
    "AA_WEIGHTS_ZZ = torch.from_numpy(class_weights)\n",
    "AA_WEIGHTS_ZZ = AA_WEIGHTS_ZZ.to(torch.float32)\n",
    "torchvision.models.detection.roi_heads.fastrcnn_loss = fastrcnn_loss_rebranded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d7f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TELECHARGEMENT DU MODELE ###\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005) # IMPROVE WITH ADAM !\n",
    "#optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a12b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████                                                                | 15/79 [20:47<4:11:33, 235.83s/it]"
     ]
    }
   ],
   "source": [
    "### ENTRAINEMENT DU MODELE ###\n",
    "\n",
    "l_losses = {'loss_classifier' : [],'loss_box_reg' : [],'loss_rpn_box_reg' : [],'loss_objectness':[]}\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_data_loader = tqdm.tqdm(train_data_loader)\n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        l_losses['loss_classifier'].append(loss_dict['loss_classifier'].item())\n",
    "        l_losses['loss_box_reg'].append(loss_dict['loss_box_reg'].item())\n",
    "        l_losses['loss_objectness'].append(loss_dict['loss_objectness'].item())\n",
    "        l_losses['loss_rpn_box_reg'].append(loss_dict['loss_rpn_box_reg'].item())\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step() \n",
    "    print('\\nTraining Loss : {:.5f}'.format(loss_value))\n",
    "    #eng.evaluate(model, validation_data_loader, device=device)\n",
    "\n",
    "## sauvegarde du modele et de ses performances\n",
    "\n",
    "\n",
    "print(\"Fin de l'entrainement, modele sauvegardé\")\n",
    "\n",
    "plot_loss_summary(l_losses,train_dataset.__len__(),num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../saved_models/\" + model_save_name)\n",
    "torch.save(model,\"../saved_models/\" + model_save_name + \"/\" + model_save_name)\n",
    "\n",
    "with open('../saved_models/'+ model_save_name +'.json', 'w') as f:\n",
    "    json.dump(l_losses, f)\n",
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
