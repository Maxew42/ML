{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfa7b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import csv\n",
    "random.seed(4)\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "#import albumentations as A\n",
    "import cv2\n",
    "from helpers.plotting import *\n",
    "from helpers.ml_utils import *\n",
    "## A nettoyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b84ddd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### DEFINITION DES FONCTIONS ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac466c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Parametrisation ###\n",
    "\n",
    "model_path = \"../saved_models/model_SGD_balanced/model_SGD_balanced\"\n",
    "name_dataset = 'dataset_Trashedy_1.0'\n",
    "path_to_data = '../dataset/'+ name_dataset + '/valid/'\n",
    "device      = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cat_to_index = {'other': 1, \n",
    "                'pet': 2,\n",
    "                'plastic_bag' : 3\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3831dd0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = ObjectDetectionDataset(path_to_dataset = path_to_data,  \n",
    "                                       transform = tensor_transform,\n",
    "                                       mapping = cat_to_index,\n",
    "                                       mode = 'test')\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19af7f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64eb9070",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-300fd3fc248e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcat_to_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fin de l'évaluation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Trashedy\\ML\\Trashedy\\notebooks\\helpers\\ml_utils.py\u001b[0m in \u001b[0;36mevaluate_to\u001b[1;34m(data_loader, device, cat_to_index, stop_number)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mdetection_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.333\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mcpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "results = evaluate_to(data_loader,device,cat_to_index,17,model)\n",
    "print(\"Fin de l'évaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76837af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_file_name = np.unique([row['file_name'] for row in results])\n",
    "n_file_name = len(l_file_name)\n",
    "n_objects = len(results)\n",
    "print(\"{} Images avec {} objets detectés\".format(n_file_name,n_objects))\n",
    "idx = int(input(\"Entrer indice de l'image à afficher : \"))\n",
    "show_result(results,path_to_data , l_file_name[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9291662",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../dataset/'+ name_dataset + '/train/'\n",
    "valid_dataset = ObjectDetectionDataset(path_to_dataset = path_to_data,  \n",
    "                                       transform = tensor_transform,\n",
    "                                       mapping = cat_to_index,\n",
    "                                       mode = 'valid')\n",
    "\n",
    "valid_data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba9686",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mapping = { value : key for (key, value) in cat_to_index.items()}\n",
    "cat = ['other','pet','plastic bag']\n",
    "nbe = 360\n",
    "\n",
    "targ = valid_dataset.__getitem__(nbe)\n",
    "img = targ[0].permute(1,2,0)\n",
    "l_boxes = targ[1]['boxes']\n",
    "labels = targ[1]['labels']\n",
    "labels = list(labels.numpy())\n",
    "labels = [cat[i-1] for i in labels]\n",
    "scores = [0.1 for i in labels]\n",
    "show_bounding_boxes(img,l_boxes,labels = labels,l_scores = scores,fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15943f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
