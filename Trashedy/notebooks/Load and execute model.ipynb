{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfa7b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import csv\n",
    "random.seed(4)\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "#import albumentations as A\n",
    "import cv2\n",
    "from helpers.plotting import *\n",
    "from helpers.ml_utils import *\n",
    "## A nettoyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac466c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Parametrisation ###\n",
    "\n",
    "model_path = \"../saved_models/model_SGD_balanced_1.2_no_kebab/model_SGD_balanced_1.2_no_kebab\"\n",
    "name_dataset = 'dataset_Trashedy_1.2_augmented'\n",
    "path_to_data = '../dataset/'+ name_dataset + '/valid/'\n",
    "device      = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cat_to_index = {'other': 1, \n",
    "                'pet': 2,\n",
    "                'plastic_bag' : 3\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3831dd0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = ObjectDetectionDataset(path_to_dataset = path_to_data,  \n",
    "                                       transform = tensor_transform,\n",
    "                                       mapping = cat_to_index,\n",
    "                                       mode = 'test')\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19af7f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb9070",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/86 [00:00<?, ?it/s]c:\\users\\maxim\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      " 29%|███████████████████████▊                                                          | 25/86 [01:11<03:04,  3.02s/it]"
     ]
    }
   ],
   "source": [
    "results = evaluate_to(data_loader,device,cat_to_index,30,model)\n",
    "print(\"Fin de l'évaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76837af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_file_name = np.unique([row['file_name'] for row in results])\n",
    "n_file_name = len(l_file_name)\n",
    "n_objects = len(results)\n",
    "print(\"{} Images avec {} objets detectés\".format(n_file_name,n_objects))\n",
    "idx = int(input(\"Entrer indice de l'image à afficher : \"))\n",
    "color_map = {'other': 'red','pet':'blue','plastic_bag':'orange'}\n",
    "show_result(results,path_to_data , l_file_name[idx],color_map = color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a02461",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_2 = '../dataset/'+ name_dataset + '/train/'\n",
    "valid_dataset = ObjectDetectionDataset(path_to_dataset = path_to_data_2,  \n",
    "                                       transform = tensor_transform,\n",
    "                                       mapping = cat_to_index,\n",
    "                                       mode = 'valid')\n",
    "\n",
    "valid_data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8589e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mapping = { value : key for (key, value) in cat_to_index.items()}\n",
    "cat = ['other','pet','plastic bag']\n",
    "nbe = 1\n",
    "\n",
    "targ = valid_dataset.__getitem__(nbe)\n",
    "img = targ[0].permute(1,2,0)\n",
    "l_boxes = targ[1]['boxes']\n",
    "labels = targ[1]['labels']\n",
    "labels = list(labels.numpy())\n",
    "labels = [cat[i-1] for i in labels]\n",
    "scores = [0.1 for i in labels]\n",
    "show_bounding_boxes(img,l_boxes,labels = labels,l_scores = scores,fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbe = 1\n",
    "\n",
    "targ = valid_dataset.__getitem__(nbe)\n",
    "img = targ[0].permute(1,2,0)\n",
    "l_boxes = targ[1]['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= list(l_boxes.numpy())\n",
    "print(a)\n",
    "b = get_intersection_area(a[5],a[6])\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
